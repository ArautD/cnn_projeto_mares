# -*- coding: utf-8 -*-
"""CNN_mares.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MzcIS9Qk4z_1loLSZvdpu2wgy_rguWCG

#Instalação e importação de bibliotecas
"""

from google.colab import drive
drive.mount('/content/drive')

# Instalação
!pip install pyrsgis
!pip install gdal
!pip install keras
!pip install tensorflow
!pip install opencv-python

import os, glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
#import gdal
from pyrsgis import raster
import tensorflow as tf
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import ImageDataGenerator

from keras.utils import to_categorical
from keras import backend as K
from tensorflow.keras.utils import to_categorical
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import Flatten
from keras.layers import Convolution2D
from keras.layers import MaxPooling2D
from keras.models import Sequential

from sklearn.metrics import confusion_matrix
import seaborn as sns; sns.set_theme()
import cv2

"""#Parâmetros e campos iniciais"""

##Parametros iniciais

#Classes e endereços das pastas das classes
#Classe 0 = indeterminado
#Classe 1 = maré baixa
#Classe 2 = maré mediana
#classe 3 = maré alta

imageDirectory_indeterminado = '/content/drive/MyDrive/projeto_mares/mares/indeterminado'
imageDirectory_mare_baixa = '/content/drive/MyDrive/projeto_mares/mares/mare_baixa'
imageDirectory_mare_mediana = '/content/drive/MyDrive/projeto_mares/mares/mare_mediana'
imageDirectory_mare_alta = '/content/drive/MyDrive/projeto_mares/mares/mare_alta'

idClass_indeterminado = 0
idClass_mare_baixa  = 1
idClass_mare_mediana = 2
idClass_mare_alta = 3

#Proporção de dados de treino teste e validação
train_ratio = 0.75
validation_ratio = 0.15
test_ratio = 0.15

#Paramêtros do Modelo
batch_size = 35
epochs = 100

"""#Área de funções"""

#Função que importa arquivos
def importImages(path_images):
  #Importando arquivos
  imageDirectory = path_images
  os.chdir(imageDirectory)
  dirFiles = os.listdir(imageDirectory)
  return dirFiles

#FUNÇÃO PARA REDIMENSIONAR AS IMAGENS (PADRONIZAR)
def resize_image(image, target_size):
    return cv2.resize(image, target_size)


#Função de Ajuste dos tipos e conversão de imagens para numpy arrays
def recover_data(path_images,idClass, target_size):

  diretoryFiles = importImages(path_images)

  arrList = []
  classList = []
  for n in diretoryFiles:
    classId = idClass
    ds, tempArr = raster.read(n)
    # print(tempArr)
    # print(tempArr.shape)
    # print(type(tempArr))
    # print(ds)
    # print('----------')
    tempArrNewDim = np.moveaxis(tempArr, 0, -1).copy() #Ajusta dimensões para (X,Y,Bandas)
    resized_image = resize_image(tempArrNewDim, target_size)
    arrList.append(resized_image)
    classList.append(classId)

  X = np.array(arrList).copy()
  y = np.array(classList).copy()
  # print(arrListImgNumPy)
  # print(classListNumPy)

  return X , y

"""#Integração dos dados"""

#Integrando dados e formando o Dataset com variaveis de entrada X, e rotulos y

X_0, y_0 = recover_data(imageDirectory_indeterminado,idClass_indeterminado, target_size=(450, 450))
X_1, y_1 = recover_data(imageDirectory_mare_baixa,idClass_mare_baixa, target_size=(450, 450))
X_2, y_2 = recover_data(imageDirectory_mare_mediana,idClass_mare_mediana, target_size=(450, 450))
X_3, y_3 = recover_data(imageDirectory_mare_alta,idClass_mare_alta, target_size=(450, 450))

X = np.concatenate((X_0, X_1, X_2, X_3)).copy()
y = np.concatenate((y_0, y_1, y_2, y_3)).copy()

# print(X[10].shape)

# print('Quantidade total de amostras:', y.shape)
# print(y)

#Visualização da quantidade de dados por classe
classes_instances_amount = np.array(np.unique(y,return_counts=True))[1]
print(classes_instances_amount)

# Make a random dataset:
bars = ('indeterminado', 'maré_baixa', 'maré_mediana', 'maré_alta')
y_pos = np.arange(len(bars))

# Create bars
plt.bar(y_pos, classes_instances_amount)
# Create names on the x-axis
plt.xticks(y_pos, bars)
# Show graphic
plt.title('Quantidade de amostras por classe.')
plt.show()

#Coletado parametros gerais
shape_img = X[0].shape
input_size_firstSide = shape_img[0]
input_size_secondSide = shape_img[1]
input_size_bands = shape_img[2]
amount_idclass = len(np.unique(y))

# print('Tamanho da entrada do primeiro lado (eixo Y da img)',input_size_firstSide)
# print('Tamanho da entrada do segundo lado (eixo X da img)',input_size_secondSide)
# print('Quantidade de bandas/cannals da img', input_size_bands)
# print('Quantidade dos ids de classes',amount_idclass)
# print('--------\n')
# print('Exibindo a primeira imagem (ou outra qualquer basntando alterar o indice de X).')
#Exibindo uma imagem.
img = X[5]
#print(img.shape)
plt.imshow(img);

"""#Pré-Processamento

##Normalização dos dados e divisão em dados de treino, validação e teste
"""

#Normalizando os valores de 0-255 to 0.0-1.0

X = X.astype('float32')#X.astype('float16') #ou -->
X /= 255.0

#Divisão dos dados em treino, teste e validação.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1 - train_ratio, stratify=y, random_state = 30)
# print(y_train)
# print(y_test)
# print("--------")
X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = test_ratio/(test_ratio + validation_ratio), stratify = y_test, random_state = 50)
# print(y_val)
# print(y_test)

# print('------')
# print("Quantidade de amostras de treino:",y_train.shape[0])
# print("Quantidade de amostras de validação:",y_val.shape[0])
# print("Quantidade de amostras de teste:",y_test.shape[0])

# # Visualizando imagens de teste
# fig, ax = plt.subplots(nrows=1, ncols=int(X_test.shape[0]), figsize=(60,60))
# # generate batch of images
# for i in range(int(X_test.shape[0])):
#   # plot image
#   ax[i].imshow(X_test[i])
#   ax[i].axis('off')

# print(y_test)

"""##Aumento e balanceamento dos dados"""

# #Data augmentation (para todo o dataset de treino) - Gera amostras de dados pela operação de flip vertical e horizontal

# datagen = ImageDataGenerator(horizontal_flip = True,vertical_flip = True)

# train_datagen = datagen.flow(X_train,y_train, batch_size=1)

# #Lista para armazenar imagens geradas
# listImgGen_train = []
# listLabelGen_train = []

# # generate samples and plot
# #fig, ax = plt.subplots(nrows=1, ncols=len(train_datagen)*2, figsize=(100,100))

# # generate batch of images
# for i in range(len(train_datagen)*2):
#   # convert to unsigned integers
#   image_label = next(train_datagen)
#   image = image_label[0][0]
#   label = image_label[1][0]
#   #print(image.shape)
#   #print(image)
#   #print(label)
#   # plot image to visualization
#   #ax[i].imshow(image)
#   #ax[i].axis('off')
#   listImgGen_train.append(image)
#   listLabelGen_train.append(label)

"""##Composição do dataset pré-treinamento"""

# #Concatenar dados de treino com dados gerados
# numpyArrimgGen_train= np.array(listImgGen_train).copy()
# X_train_gen = np.concatenate((X_train, numpyArrimgGen_train)).copy()

# numpyArrLabelGen_train = np.array(listLabelGen_train).copy()
# print('Quantidade de amostras dos dados de treino geradas', numpyArrLabelGen_train.shape)
# y_train_gen = np.concatenate((y_train, numpyArrLabelGen_train)).copy()
# print('Quantidade de dados de treinos + amostras geradas', y_train_gen.shape)

#Transformando os rótulos de decimal para vetores com valores binários
y_train = to_categorical(y_train).copy()
y_val = to_categorical(y_val).copy()
y_test = to_categorical(y_test).copy()

"""#Treinamento do modelo

##Construção do modelo de aprendizado de máquina
"""

# Configuração do Modelo
K.set_image_data_format('channels_last')

#Criação do Modelo
model = Sequential()
model.add(Convolution2D(32, (3, 3), input_shape=(input_size_firstSide, input_size_secondSide, input_size_bands), activation="relu", padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Convolution2D(32, (3, 3), activation="relu", padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Convolution2D(64, (3, 3), activation="relu", padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Convolution2D(128, (3, 3), activation="relu", padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Convolution2D(256, (3, 3), activation="relu", padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Convolution2D(512, (3, 3), activation="relu", padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Convolution2D(1024, (3, 3), activation="relu", padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(128, activation="relu"))
model.add(Dense(64, activation="relu"))
model.add(Dropout(0.2))
model.add(Dense(amount_idclass, activation="softmax"))
model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
model.summary()

# #Visualização do modelo da visualização
# #from ann_visualizer.visualize import ann_viz;
# # Salva um pdf na pasta com a imagem
# #ann_viz(model, title="")
# #Visualização do modelo da visualização
# import visualkeras
# visualkeras.layered_view(model,legend=True,draw_volume=False,to_file='/content/drive/MyDrive/projeto_mares/figs/vis_modelGeneral.png')

"""##Executa treinamento do modelo"""

# # Utilizar o acelerador de GPU do colab (para treinamento)
# import tensorflow as tf

# # device_name = tf.test.gpu_device_name()
# # if device_name != '/device:GPU:0':
# #   raise SystemError('GPU device not found')

# print('Found GPU at: {}'.format(device_name))
# tf.device('/device:GPU:0')
# print()

# physical_devices = tf.config.experimental.list_logical_devices('GPU')
# print("GPUs available: ", physical_devices)
# print("GPUs available: ", len(physical_devices))
# # print(physical_devices[0].name)
# print()

# # Qual placa de video GPU estou usando?
# from tensorflow.python.client import device_lib
# device_lib.list_local_devices()
# print(device_lib.list_local_devices())

# Executa o treinamento do modelo
history = model.fit(X_train, y_train, epochs=100, batch_size=30, validation_data=(X_val, y_val))

"""#Avaliação do modelo"""

# Plota o histórico da curva de acuracia sobre dados de validação
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Learning curve')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='lower right')
plt.savefig('/content/drive/MyDrive/projeto_mares/figs/curve_accuracyTrain.png', dpi=300)
plt.show()

# Plota o histórico da curva de acuracia sobre dados de validação
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Loss curve')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='lower right')
plt.savefig('/content/drive/MyDrive/projeto_mares/figs/curve_lossTrain.png', dpi=300)
plt.show()

# Mostra a acurácia geral sobre dados de teste
scores = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)
acc_general = str("%.2f"%(scores[1]))
print("CNN Score acuracia:", acc_general)
print(scores)

print(X_test.shape)
#Gerar matrix de confusão
y_pred_aux = model.predict(X_test, verbose=0)
print(y_pred_aux)
y_pred = np.argmax(y_pred_aux,axis=1)
print(y_pred)
print('---------')
y_actu = np.argmax(y_test,axis=1)
print(y_test)
print(y_actu)

matrix_confusion = confusion_matrix(y_actu, y_pred)
s = sns.heatmap(matrix_confusion, square=True, annot=True, cmap='Blues', fmt='d', cbar=False);
s.set(xlabel='Predict', ylabel='Actual')
s.figure.savefig('/content/drive/MyDrive/projeto_mares/figs/confusion_matrix.png')

"""##Exportação do modelo"""

model.save('/content/drive/MyDrive/projeto_mares/models/CNN_MARE_model.h5')